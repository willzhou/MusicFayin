# Author: Ningbo Wise Effects, Inc. (æ±‡è§†åˆ›å½±) & Will Zhou
# License: Apache 2.0

import streamlit as st
import json
import requests
from datetime import datetime
import os
import subprocess
import torch

from typing import Dict, Any, List, Tuple, Optional
import psutil
import sys
from pathlib import Path
import re

# import glob
# import time
# import threading
# from .config import DEEPSEEK_API_KEY, DEEPSEEK_URL

from config import EMOTIONS, SINGER_GENDERS, GENRES, INSTRUMENTATIONS, TIMBRES, AUTO_PROMPT_TYPES
from config import MUSIC_SECTION_TEMPLATES, STRUCTURE_TEMPLATES, SECTION_DEFINITIONS

from api_handlers import call_deepseek_api, analyze_lyrics
from func_utils import (
    get_absolute_path,
    parse_duration_to_seconds,
    calculate_section_timings,
    clean_generated_lyrics,
    get_gpu_memory,
    save_jsonl
)
from config import DEFAULT_BPM

# åœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ é¡¹ç›®æ ¹ç›®å½•å®šä¹‰
PROJECT_ROOT = Path(__file__).parent  # å‡è®¾musicfayin.pyç°åœ¨æ”¾åœ¨SongGenerationçš„çˆ¶ç›®å½•
SONG_GEN_DIR = PROJECT_ROOT / "SongGeneration"
 
# åˆå§‹åŒ–session state
if 'app_state' not in st.session_state:
    st.session_state.app_state = {
        'lyrics': None,
        'analysis_result': None,
        'singer_gender': SINGER_GENDERS[0],
        'generated_jsonl': None,
        'music_files': []
    }
  

# ========================
# è¾…åŠ©å‡½æ•°
# ========================
def format_section_timing(sections: List[str], timings: Dict[str, int]) -> str:
    """æ ¼å¼åŒ–æ®µè½æ—¶é•¿ä¿¡æ¯"""
    return "\n".join(
        f"- [{sec}]: {timings[sec]}ç§’" + 
        f" ({MUSIC_SECTION_TEMPLATES[sec]['description']})" 
        for sec in sections
    )

def calc_lines_from_seconds(seconds: int) -> str:
    """æ ¹æ®ç§’æ•°è®¡ç®—å»ºè®®è¡Œæ•°"""
    min_lines = max(2, seconds // 5)  # æ¯è¡Œæœ€å¤š5ç§’
    max_lines = max(4, seconds // 3)  # æ¯è¡Œæœ€å°‘3ç§’
    return f"{min_lines}-{max_lines}è¡Œ"


def generate_lyrics_with_duration(
    lyric_prompt: str,
    template: Dict[str, Any],
    song_length: str
) -> Optional[str]:
    """ç”Ÿæˆå¸¦æ—¶é•¿æ§åˆ¶çš„æ­Œè¯"""
    try:
        # è§£ææ€»æ—¶é•¿
        total_seconds = parse_duration_to_seconds(song_length)
        
        # è®¡ç®—æ®µè½æ—¶é•¿
        section_timings = calculate_section_timings(template["sections"], total_seconds)
        
        # æ„å»ºæç¤ºè¯
        prompt_lines = [
            f"è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚ç”Ÿæˆä¸€é¦–ä¸­æ–‡æ­Œæ›²çš„å®Œæ•´æ­Œè¯ï¼š\n"
            f"ä¸»é¢˜ï¼š{lyric_prompt}",
            f"""æ­Œæ›²ç»“æ„ï¼š
            {", ".join([f"[{section}]" for section in template["sections"]])}
            å…·ä½“è¦æ±‚ï¼š
            1. ä¸¥æ ¼æŒ‰ç…§ç»™å®šçš„ç»“æ„æ ‡ç­¾åˆ†æ®µ
            2. å™¨ä¹æ®µè½([intro-*]/[outro-*])ä¸éœ€è¦å¡«æ­Œè¯
            3. äººå£°æ®µè½([verse]/[chorus]/[bridge])å¿…é¡»åŒ…å«æ­Œè¯
            4. ä¸»æ­Œ([verse])æ¯æ®µ4-8è¡Œ
            5. å‰¯æ­Œ([chorus])è¦çªå‡ºé«˜æ½®éƒ¨åˆ†
            6. æ¡¥æ®µ([bridge])2-4è¡Œ
            7. æ•´ä½“è¦æœ‰æŠ¼éŸµå’ŒèŠ‚å¥æ„Ÿ
            8. ä¸è¦åŒ…å«æ­Œæ›²æ ‡é¢˜
            9. ä¸è¦åŒ…å«éŸµè„šåˆ†æç­‰é¢å¤–è¯´æ˜
            è¿”å›æ ¼å¼ç¤ºä¾‹ï¼š
            [intro-medium]
            [verse]
            ç¬¬ä¸€è¡Œæ­Œè¯
            ç¬¬äºŒè¡Œæ­Œè¯
            ...
            [chorus]
            å‰¯æ­Œç¬¬ä¸€è¡Œ
            å‰¯æ­Œç¬¬äºŒè¡Œ
            ...""",
            f"æ€»æ—¶é•¿ï¼š{song_length} ({total_seconds}ç§’)",
            "æ®µè½æ—¶é•¿åˆ†é…ï¼š"
        ]
        
        # æ·»åŠ å„æ®µè½ä¿¡æ¯
        for section in template["sections"]:
            desc = MUSIC_SECTION_TEMPLATES[section]["description"]
            prompt_lines.append(f"- [{section}]: {section_timings[section]}ç§’ ({desc})")
        
        # æ·»åŠ æ­Œè¯è¡Œæ•°è¦æ±‚
        prompt_lines.append("\næ­Œè¯è¦æ±‚ï¼š")
        prompt_lines.append(f"1. ä¸»æ­Œ([verse]): æ¯æ®µ{calc_lines_from_seconds(section_timings['verse'])}è¡Œ")
        prompt_lines.append(f"2. å‰¯æ­Œ([chorus]): æ¯æ®µ{calc_lines_from_seconds(section_timings['chorus'])}è¡Œ")
        
        # åªæœ‰æ¨¡æ¿åŒ…å«bridgeæ—¶æ‰æ·»åŠ bridgeè¦æ±‚
        if "bridge" in template["sections"]:
            prompt_lines.append(f"3. æ¡¥æ®µ([bridge]): {calc_lines_from_seconds(section_timings['bridge'])}è¡Œ")
        
        prompt_lines.append("4. å™¨ä¹æ®µè½ä¸éœ€è¦æ­Œè¯")
        prompt_lines.append("5. æ³¨æ„æŠ¼éŸµå’ŒèŠ‚å¥")
        
        prompt = "\n".join(prompt_lines)
        
        return call_deepseek_api(prompt)
    except Exception as e:
        st.error(f"æ­Œè¯ç”Ÿæˆå¤±è´¥: {str(e)}")
        return None

    

def generate_jsonl_entries(prefix: str, lyrics: str, analysis: Dict[str, Any], prompt_audio_path: str = "input/sample_prompt_audio.wav") -> List[Dict]:
    """ç”Ÿæˆæ‰€æœ‰JSONLæ¡ç›®"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    entries = [
        {
            "idx": f"{prefix}_autoprompt_{timestamp}",
            "gt_lyric": lyrics,
            "auto_prompt_audio_type": "Auto"
        },
        {
            "idx": f"{prefix}_noprompt_{timestamp}",
            "gt_lyric": lyrics
        },
        {
            "idx": f"{prefix}_textprompt_{timestamp}",
            "descriptions": (
                f"{analysis['gender_suggestion']}, {analysis['timbre']}, "
                f"{analysis['genre']}, {analysis['emotion']}, "
                f"{analysis['instrumentation']}, the bpm is {analysis.get('bpm', DEFAULT_BPM)}"
            ),
            "gt_lyric": lyrics
        },
        {
            "idx": f"{prefix}_audioprompt_{timestamp}",
            "gt_lyric": lyrics,
            "prompt_audio_path": prompt_audio_path
        }
    ]
    
    return entries


# åœ¨å…¨å±€å˜é‡æˆ–session_stateä¸­æ·»åŠ è¿è¡ŒçŠ¶æ€æ ‡å¿—
if 'running_process' not in st.session_state:
    st.session_state.running_process = None

def run_music_generation(jsonl_path: str, output_dir: str = "output", 
                        force_standard: bool = False, gen_type: str = ""):
    """æ‰§è¡ŒéŸ³ä¹ç”Ÿæˆå‘½ä»¤ï¼ˆå¸¦é˜²æ­¢é‡å¤è¿è¡Œæœºåˆ¶ï¼‰"""
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰è¿›ç¨‹åœ¨è¿è¡Œ
    if st.session_state.running_process is not None:
        st.warning("âš ï¸ å·²æœ‰ç”Ÿæˆä»»åŠ¡æ­£åœ¨è¿è¡Œï¼Œè¯·ç­‰å¾…å®Œæˆ")
        return
    
    try:
        # è·å–æ˜¾å­˜ä¿¡æ¯
        gpu_info = get_gpu_memory()
        
        # å†³å®šä½¿ç”¨å“ªä¸ªè„šæœ¬
        if force_standard:
            script = "generate.sh"
            st.info("å·²å¼ºåˆ¶ä½¿ç”¨æ ‡å‡†ç”Ÿæˆæ¨¡å¼(generate.sh)")
        elif gpu_info and gpu_info["total"] >= 30:
            script = "generate.sh"
            st.info(f"æ£€æµ‹åˆ°å……è¶³æ˜¾å­˜ ({gpu_info['total']:.1f}GB)ï¼Œå°†ä½¿ç”¨æ ‡å‡†ç”Ÿæˆæ¨¡å¼")
        else:
            script = "generate_lowmem.sh"
            st.warning(f"æ˜¾å­˜ä¸è¶³30GB ({gpu_info['total']:.1f}GB if available)ï¼Œä½¿ç”¨ä½æ˜¾å­˜æ¨¡å¼")
        
        # ä½¿ç”¨ç»å¯¹è·¯å¾„
        cmd = [
            "bash",
            str(SONG_GEN_DIR / script),
            str(SONG_GEN_DIR / "ckpt/songgeneration_base/"),
            str(get_absolute_path(jsonl_path)),
            str(get_absolute_path(output_dir))
        ]
        
        # æ·»åŠ ç”Ÿæˆç±»å‹å‚æ•°
        if gen_type:
            cmd.append(gen_type)
        
        # æ˜¾ç¤ºæ‰§è¡Œå‘½ä»¤
        st.code(" ".join(cmd), language="bash")

        # æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯
        status_text = st.empty()
        status_text.text("éŸ³ä¹ç”Ÿæˆä¸­ï¼Œè¯·æŸ¥çœ‹ç»ˆç«¯è¾“å‡º...")
        
        # åˆ›å»ºè¿›ç¨‹é”æ–‡ä»¶
        lock_file = Path(output_dir) / "generation.lock"
        if lock_file.exists():
            st.error("âŒ æ£€æµ‹åˆ°å·²æœ‰ç”Ÿæˆè¿›ç¨‹è¿è¡Œï¼Œè¯·åˆ é™¤lockæ–‡ä»¶åå†è¯•")
            return
            
        try:
            # åˆ›å»ºé”æ–‡ä»¶
            lock_file.touch()
            
            # æ‰§è¡Œå‘½ä»¤ - ç›´æ¥è¾“å‡ºåˆ°ç»ˆç«¯
            process = subprocess.Popen(
                cmd,
                cwd=str(SONG_GEN_DIR),
                stdout=sys.stdout,
                stderr=sys.stderr,
                universal_newlines=True
            )
            
            # ä¿å­˜è¿›ç¨‹åˆ°session state
            st.session_state.running_process = process
            
            # ç­‰å¾…å‘½ä»¤å®Œæˆ
            return_code = process.wait()
            
        finally:
            # æ— è®ºæˆåŠŸå¤±è´¥éƒ½æ¸…ç†é”æ–‡ä»¶å’Œè¿›ç¨‹çŠ¶æ€
            if lock_file.exists():
                lock_file.unlink()
            st.session_state.running_process = None
            status_text.empty()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶
        audio_files = list(Path(get_absolute_path(output_dir)).glob("audios/*.flac"))
        
        # å¤„ç†ç»“æœ
        if audio_files:
            st.success("ğŸµ éŸ³ä¹ç”Ÿæˆå®Œæˆï¼")
            display_generated_files(output_dir)
            
            if return_code != 0:
                st.warning(f"âš ï¸ ç”Ÿæˆè¿‡ç¨‹å‡ºç°è­¦å‘Š (è¿”å›ç : {return_code})")
        else:
            if return_code == 0:
                st.error("âŒ ç”Ÿæˆè¿‡ç¨‹å®Œæˆä½†æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
            else:
                st.error(f"âŒ ç”Ÿæˆå¤±è´¥ (è¿”å›ç : {return_code})")
                
    except Exception as e:
        st.error(f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        if 'lock_file' in locals() and lock_file.exists():
            lock_file.unlink()
        st.session_state.running_process = None


def display_generated_files(output_dir: str):
    """æ˜¾ç¤ºç”Ÿæˆçš„éŸ³ä¹æ–‡ä»¶"""
    audio_files = list(Path(output_dir).glob("audios/*.flac"))
    if not audio_files:
        st.warning("æœªæ‰¾åˆ°ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶")
        return
    
    st.subheader("ç”Ÿæˆçš„éŸ³ä¹")
    for audio_file in sorted(audio_files):
        col1, col2 = st.columns([3, 1])
        with col1:
            st.audio(str(audio_file))
        with col2:
            with open(audio_file, "rb") as f:
                st.download_button(
                    "ä¸‹è½½",
                    data=f.read(),
                    file_name=audio_file.name,
                    mime="audio/flac"
                )



def replace_chinese_punctuation(text):
    """æ›¿æ¢ä¸­æ–‡æ ‡ç‚¹ä¸ºè‹±æ–‡æ ‡ç‚¹"""
    punctuation_map = {
        'ï¼Œ': ',', 'ã€‚': '.', 'ã€': ',', 'ï¼›': ';', 'ï¼š': ':',
        'ï¼Ÿ': '?', 'ï¼': '!', 'ã€Œ': '"', 'ã€': '"', 'ã€': '"',
        'ã€': '"', 'ï¼ˆ': '(', 'ï¼‰': ')', 'ã€Š': '"', 'ã€‹': '"'
    }
    
    # é€ä¸ªå­—ç¬¦æ›¿æ¢
    result = []
    for char in text:
        if char in punctuation_map:
            # åœ¨æ ‡ç‚¹å‰åæ·»åŠ ç©ºæ ¼ç¡®ä¿åˆ†å‰²
            result.append(f" {punctuation_map[char]} ")
        else:
            result.append(char)
    
    # åˆå¹¶å¹¶æ ‡å‡†åŒ–ç©ºæ ¼
    return re.sub(r'\s+', ' ', "".join(result)).strip()


import plotly.express as px
def display_duration_breakdown(sections: List[str], total_seconds: int):
    """æ˜¾ç¤ºæ—¶é•¿åˆ†é…é¥¼å›¾"""
    timings = calculate_section_timings(sections, total_seconds)
    
    fig = px.pie(
        names=[f"[{sec}]" for sec in sections],
        values=[timings[sec] for sec in sections],
        title=f"æ—¶é•¿åˆ†é… (æ€»è®¡: {total_seconds}ç§’)",
        color_discrete_sequence=px.colors.sequential.RdBu
    )
    st.plotly_chart(fig, use_container_width=True)


# å…¸å‹ç»“æ„æ¨¡æ¿
# ========================
# Streamlit ç•Œé¢
# ========================
def setup_ui():
    """è®¾ç½®Streamlitç”¨æˆ·ç•Œé¢"""
    st.set_page_config(page_title="MusicFayIn", layout="wide")
    st.title("ğŸµ MusicFayIn äººå·¥æ™ºèƒ½éŸ³ä¹ç”Ÿæˆç³»ç»Ÿ")
    
    # æ­¥éª¤1: æ­Œè¯ç”Ÿæˆ
    st.header("ç¬¬ä¸€æ­¥: ç”Ÿæˆæ­Œè¯")
    
    col1, col2 = st.columns([3, 2])
    
    with col1:
        lyric_prompt = st.text_area("è¾“å…¥æ­Œè¯ä¸»é¢˜", "å¦‚æœèƒ½é‡æ¥")
        
        # æ–°å¢æ—¶é•¿é€‰æ‹©å™¨
        length_min = st.slider(
            "æ­Œæ›²æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰", 
            min_value=1, 
            max_value=10, 
            value=2,
            step=1
        )
        length_sec = st.slider(
            "æ­Œæ›²æ—¶é•¿ï¼ˆç§’ï¼‰", 
            min_value=0, 
            max_value=59, 
            value=30,
            step=5
        )
        song_length = f"{length_min}åˆ†{length_sec}ç§’"
        
        # ç»“æ„æ¨¡æ¿é€‰æ‹©
        selected_template = st.selectbox(
            "é€‰æ‹©æ­Œæ›²ç»“æ„æ¨¡æ¿",
            options=list(STRUCTURE_TEMPLATES.keys()),
            format_func=lambda x: STRUCTURE_TEMPLATES[x]["name"]
        )
        
        # æ˜¾ç¤ºé€‰ä¸­çš„æ¨¡æ¿ç»“æ„
        if selected_template:
            template = STRUCTURE_TEMPLATES[selected_template]
            st.markdown("**å½“å‰ç»“æ„:**")
            for i, section in enumerate(template["sections"]):
                info = MUSIC_SECTION_TEMPLATES[section]
                st.markdown(f"{i+1}. `[{section}]` - {info['description']}")
                
    with col2:
        # æ˜¾ç¤ºæ®µè½æ—¶é•¿è¯´æ˜
        st.markdown("### ğŸµ éŸ³ä¹æ®µè½æ—¶é•¿è§„èŒƒ")
        st.markdown("""
        **ä¸€ã€çº¯å™¨ä¹æ®µè½ï¼ˆä¸å«æ­Œè¯ï¼‰:**
        - `[intro-short]`: å‰å¥è¶…çŸ­ç‰ˆ (0-10ç§’)
        - `[outro-short]`: å°¾å¥è¶…çŸ­ç‰ˆ (0-10ç§’)
        - `[intro-medium]`: å‰å¥ä¸­ç­‰ç‰ˆ (10-20ç§’)
        - `[outro-medium]`: å°¾å¥ä¸­ç­‰ç‰ˆ (10-20ç§’)
        
        **äºŒã€äººå£°æ®µè½ï¼ˆå¿…é¡»å«æ­Œè¯ï¼‰:**
        - `[verse]`: ä¸»æ­Œ (20-30ç§’, 4-8è¡Œ)
        - `[chorus]`: å‰¯æ­Œ (é«˜æ½®æ®µè½, 20-30ç§’)
        - `[bridge]`: è¿‡æ¸¡æ¡¥æ®µ (15-25ç§’, 2-4è¡Œ)
        """)
        
        st.markdown("### ğŸ“ ä½¿ç”¨å»ºè®®")
        st.markdown("""
        - å™¨ä¹æ®µè½ä¸¥æ ¼æŒ‰ç§’æ•°èŒƒå›´æ§åˆ¶
        - äººå£°æ®µè½é€šè¿‡æ­Œè¯è¡Œæ•°æ§åˆ¶æ—¶é•¿
        - å‰å¥/å°¾å¥è‹¥è¶…è¿‡20ç§’ï¼Œå¯ç»„åˆä½¿ç”¨:
          `[intro-medium][intro-short]` â‰ˆ 25ç§’
        """)

    # ç”Ÿæˆæ­Œè¯æŒ‰é’®
    if st.button("ç”Ÿæˆæ­Œè¯"):
        with st.spinner(f"æ­£åœ¨ç”Ÿæˆ{song_length}çš„æ­Œè¯..."):
            template = STRUCTURE_TEMPLATES[selected_template]
            lyrics = generate_lyrics_with_duration(
                lyric_prompt=lyric_prompt,
                template=template,
                song_length=song_length
            )

            if lyrics:
                cleaned_lyrics = clean_generated_lyrics(lyrics)
                st.session_state.app_state['lyrics'] = cleaned_lyrics
                st.text_area("ç”Ÿæˆçš„æ­Œè¯", cleaned_lyrics, height=200)
                
                # æ˜¾ç¤ºæ—¶é•¿åˆ†é…
                total_seconds = parse_duration_to_seconds(song_length)
                st.subheader("æ—¶é•¿åˆ†é…è¯¦æƒ…")
                display_duration_breakdown(template["sections"], total_seconds)

                # è‡ªåŠ¨åˆ†ææ­Œè¯å‚æ•°
                with st.spinner("æ­£åœ¨åˆ†ææ­Œè¯ç‰¹å¾..."):
                    analysis = analyze_lyrics(cleaned_lyrics)
                    if analysis:
                        st.session_state.app_state['analysis_result'] = analysis
                        st.success("æ­Œè¯åˆ†æå®Œæˆï¼")

    # æ­¥éª¤2: åˆ†ææ­Œè¯
    if st.session_state.app_state.get('lyrics'):
        st.header("ç¬¬äºŒæ­¥: åˆ†ææ­Œè¯")
        
        if st.button("åˆ†ææ­Œè¯å‚æ•°"):
            with st.spinner("æ­£åœ¨åˆ†ææ­Œè¯..."):
                analysis = analyze_lyrics(st.session_state.app_state['lyrics'])
                if analysis:
                    st.session_state.app_state['analysis_result'] = analysis
                    st.json(analysis)

    # æ­¥éª¤3: å‚æ•°è°ƒæ•´
    if st.session_state.app_state.get('analysis_result'):
        st.header("ç¬¬ä¸‰æ­¥: å‚æ•°è°ƒæ•´")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # ä½¿ç”¨åˆ†æç»“æœæˆ–æä¾›é»˜è®¤å€¼
            default_gender = st.session_state.app_state['analysis_result'].get(
                'gender_suggestion', SINGER_GENDERS[0]
            )
            st.session_state.app_state['singer_gender'] = st.radio(
                "æ­Œæ‰‹æ€§åˆ«", SINGER_GENDERS,
                index=SINGER_GENDERS.index(default_gender),
                horizontal=True
            )
            
            default_emotion = st.session_state.app_state['analysis_result'].get(
                'emotion', EMOTIONS[0]
            )
            st.session_state.app_state['analysis_result']['emotion'] = st.selectbox(
                "æƒ…ç»ª", EMOTIONS,
                index=EMOTIONS.index(default_emotion)
            )
            
            default_timbre = st.session_state.app_state['analysis_result'].get(
                'timbre', TIMBRES[0]
            )
            st.session_state.app_state['analysis_result']['timbre'] = st.selectbox(
                "éŸ³è‰²", TIMBRES,
                index=TIMBRES.index(default_timbre)
            )
        
        with col2:
            default_genre = st.session_state.app_state['analysis_result'].get(
                'genre', GENRES[0]
            )
            st.session_state.app_state['analysis_result']['genre'] = st.selectbox(
                "æ­Œæ›²ç±»å‹", GENRES,
                index=GENRES.index(default_genre.split(",")[0])  # å–ç¬¬ä¸€ä¸ªç±»å‹
            )
            
            default_instrument = st.session_state.app_state['analysis_result'].get(
                'instrumentation', INSTRUMENTATIONS[0]
            )
            st.session_state.app_state['analysis_result']['instrumentation'] = st.selectbox(
                "ä¹å™¨ç»„åˆ", INSTRUMENTATIONS,
                index=INSTRUMENTATIONS.index(default_instrument)
            )
        with col3:
            # æ·»åŠ BPMæ§åˆ¶
            default_bpm = st.session_state.app_state['analysis_result'].get('bpm', DEFAULT_BPM)
            st.session_state.app_state['analysis_result']['bpm'] = st.slider(
                "BPM (æ¯åˆ†é’ŸèŠ‚æ‹æ•°)",
                min_value=60,
                max_value=160,
                value=default_bpm,
                step=1,
                help="å»ºè®®å€¼: æ…¢é€Ÿ60-80, ä¸­é€Ÿ80-120, å¿«é€Ÿ120-160"
            )
            
            # æ˜¾ç¤ºBPMå¯¹åº”çš„éŸ³ä¹ç±»å‹
            bpm = st.session_state.app_state['analysis_result']['bpm']
            tempo_type = "slow" if bpm < 80 else ("fast" if bpm > 120 else "medium")
            st.markdown(f"**é€Ÿåº¦ç±»å‹**: {tempo_type} ({bpm} BPM)")
            
            # å¯è§†åŒ–BPM
            st.markdown("**èŠ‚å¥å‚è€ƒ**:")
            if bpm < 80:
                st.markdown("ğŸµ æ…¢é€Ÿ (æŠ’æƒ…ã€æ°‘è°£)")
            elif 80 <= bpm <= 120:
                st.markdown("ğŸµ ä¸­é€Ÿ (æµè¡Œã€æ‘‡æ»š)")
            else:
                st.markdown("ğŸµ å¿«é€Ÿ (èˆæ›²ã€ç”µå­)")

    # æ­¥éª¤4: ç”ŸæˆJSONL
    if st.session_state.app_state.get('analysis_result'):
        st.header("ç¬¬å››æ­¥: ç”Ÿæˆé…ç½®")
        
        prefix = st.text_input("IDå‰ç¼€", "sample_01")
        
        # æ·»åŠ ç”Ÿæˆç±»å‹é€‰æ‹©
        gen_type = st.radio(
            "ç”Ÿæˆç±»å‹",
            options=["", "bgm", "vocal"],
            format_func=lambda x: {
                "": "å®Œæ•´æ­Œæ›²",
                "bgm": "çº¯éŸ³ä¹(BGM)", 
                "vocal": "çº¯äººå£°"
            }[x],
            horizontal=True,
            help="é€‰æ‹©ç”Ÿæˆå®Œæ•´æ­Œæ›²ã€çº¯èƒŒæ™¯éŸ³ä¹æˆ–çº¯äººå£°"
        )
        
        # è®¾ç½®é»˜è®¤è·¯å¾„æˆ–ç”¨æˆ·é€‰æ‹©çš„è·¯å¾„
        prompt_audio_path = "input/sample_prompt_audio.wav"  # é»˜è®¤å€¼
        
        # æ·»åŠ éŸ³é¢‘æ–‡ä»¶é€‰æ‹©å™¨
        uploaded_file = st.file_uploader(
            "é€‰æ‹©éŸ³é¢‘æç¤ºæ–‡ä»¶ï¼ˆé»˜è®¤ï¼šinput/sample_prompt_audio.wavï¼‰",
            type=["wav","mp3","flac"],
            help="è¯·é€‰æ‹©ç”¨äºéŸ³é¢‘æç¤ºçš„.wavæ–‡ä»¶"
        )

        if uploaded_file is not None:
            input_dir = get_absolute_path("input")
            input_dir.mkdir(parents=True, exist_ok=True)
            prompt_audio_path = input_dir / uploaded_file.name
            with open(prompt_audio_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            st.success(f"æ–‡ä»¶å·²ä¿å­˜: {prompt_audio_path}")
            prompt_audio_path = str(prompt_audio_path)  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä¾›åç»­ä½¿ç”¨

                
        if st.button("ç”ŸæˆJSONLé…ç½®"):
            entries = generate_jsonl_entries(
                prefix,
                st.session_state.app_state['lyrics'],
                st.session_state.app_state['analysis_result'],
                prompt_audio_path  # ä¼ å…¥è‡ªå®šä¹‰çš„éŸ³é¢‘è·¯å¾„
            )
            
            filename = f"{prefix}_config_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jsonl"
            filepath = save_jsonl(entries, filename)
            
            st.session_state.app_state['generated_jsonl'] = filepath
            st.success(f"JSONLæ–‡ä»¶å·²ç”Ÿæˆ: {filepath}")
            
            for entry in entries:
                st.json(entry)

    # æ­¥éª¤5: ç”ŸæˆéŸ³ä¹
    if st.session_state.app_state.get('generated_jsonl'):
        st.header("ç¬¬äº”æ­¥: ç”ŸæˆéŸ³ä¹")
        
        # è¾“å‡ºç›®å½•è®¾ç½®
        output_dir = st.text_input("è¾“å‡ºç›®å½•", "output")
        
        # æ·»åŠ å¼ºåˆ¶ä½¿ç”¨generate.shçš„é€‰é¡¹
        col1, col2 = st.columns(2)
        with col1:
            force_standard = st.checkbox(
                "å¼ºåˆ¶ä½¿ç”¨æ ‡å‡†æ¨¡å¼(generate.sh)", 
                help="å¿½ç•¥æ˜¾å­˜æ£€æµ‹ï¼Œå¼ºåˆ¶ä½¿ç”¨æ ‡å‡†ç”Ÿæˆæ¨¡å¼(éœ€è¦30GBä»¥ä¸Šæ˜¾å­˜)"
            )
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        try:
            # éªŒè¯æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            required_files = [
                SONG_GEN_DIR / "ckpt/songgeneration_base/config.yaml",
                SONG_GEN_DIR / "ckpt/songgeneration_base/model.pt",
                SONG_GEN_DIR / "ckpt/model_1rvq/model_2_fixed.safetensors",
                SONG_GEN_DIR / "ckpt/model_septoken/model_2.safetensors",
                SONG_GEN_DIR / "ckpt/prompt.pt"
            ]
            
            missing_files = [f for f in required_files if not os.path.exists(f)]
                        
            if missing_files:
                raise FileNotFoundError(
                    f"ç¼ºå°‘å¿…è¦çš„æ¨¡å‹æ–‡ä»¶:\n{chr(10).join(missing_files)}\n"
                    "è¯·ç¡®ä¿æ–‡ä»¶ç»“æ„å¦‚ä¸‹:\n"
                    "ckpt/\n"
                    "â”œâ”€â”€ model_1rvq/\n"
                    "â”‚   â””â”€â”€ model_2_fixed.safetensors\n"
                    "â”œâ”€â”€ model_septoken/\n"
                    "â”‚   â””â”€â”€ model_2.safetensors\n"
                    "â”œâ”€â”€ prompt.pt\n"
                    "â””â”€â”€ songgeneration_base/\n"
                    "    â”œâ”€â”€ config.yaml\n"
                    "    â””â”€â”€ model.pt"
                )
            
            st.success("âœ… æ¨¡å‹æ–‡ä»¶éªŒè¯é€šè¿‡")
            
            if st.button("è¿è¡ŒéŸ³ä¹ç”Ÿæˆ"):
                # # å‡†å¤‡ç”Ÿæˆå‘½ä»¤
                jsonl_path = st.session_state.app_state['generated_jsonl']
                
                gpu_info = get_gpu_memory()
                if gpu_info:
                    st.info(f"å½“å‰GPUæ˜¾å­˜: {gpu_info['total']:.1f}GB (å·²ç”¨: {gpu_info['used']:.1f}GB)")
                    
                # ä¿®æ”¹run_music_generationè°ƒç”¨ï¼Œä¼ å…¥force_standardå‚æ•°
                run_music_generation(
                    jsonl_path=jsonl_path,
                    output_dir=output_dir,
                    force_standard=force_standard,
                    gen_type=gen_type  # ä¼ å…¥ç”Ÿæˆç±»å‹
                )     
                
                # åœ¨ç”ŸæˆéŸ³ä¹éƒ¨åˆ†æ·»åŠ å–æ¶ˆæŒ‰é’®
                if st.session_state.get('running_process'):
                    if st.button("å–æ¶ˆç”Ÿæˆ"):
                        try:
                            st.session_state.running_process.terminate()
                            st.success("å·²å‘é€ç»ˆæ­¢ä¿¡å·ï¼Œè¯·ç­‰å¾…è¿›ç¨‹ç»“æŸ")
                        except Exception as e:
                            st.error(f"ç»ˆæ­¢å¤±è´¥: {str(e)}")
                                           
                # åˆ›å»ºè¿›åº¦æ¡
                # progress_bar = st.progress(0)
                status_text = st.empty()
                status_text.text("éŸ³ä¹ç”Ÿæˆä¸­...")

        except FileNotFoundError as e:
            st.error(str(e))
            st.warning("è¯·ç¡®ä¿æ‰€æœ‰æ¨¡å‹æ–‡ä»¶å·²æ­£ç¡®ä¸‹è½½å¹¶æ”¾ç½®åœ¨æŒ‡å®šä½ç½®")
        except Exception as e:
            st.error(f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")


    # ä¾§è¾¹æ è¯´æ˜
    st.sidebar.markdown("""
    ### ä½¿ç”¨æµç¨‹
    1. **ç”Ÿæˆæ­Œè¯**ï¼šè¾“å…¥ä¸»é¢˜ç”Ÿæˆæ­Œè¯
    2. **åˆ†ææ­Œè¯**ï¼šè‡ªåŠ¨åˆ†æéŸ³ä¹å‚æ•°
    3. **è°ƒæ•´å‚æ•°**ï¼šæ ¹æ®éœ€è¦ä¿®æ”¹å‚æ•°
    4. **ç”Ÿæˆé…ç½®**ï¼šåˆ›å»ºJSONLé…ç½®æ–‡ä»¶
    5. **ç”ŸæˆéŸ³ä¹**ï¼šè¿è¡Œç”Ÿæˆè„šæœ¬

    ### ç”Ÿæˆé€‰é¡¹
    - è‡ªåŠ¨ç”Ÿæˆ (autoprompt)
    - æ— æç¤ºç”Ÿæˆ (noprompt)
    - æ–‡æœ¬æç¤ºç”Ÿæˆ (textprompt)
    - éŸ³é¢‘æç¤ºç”Ÿæˆ (audioprompt)
    """)

    # ç³»ç»Ÿç›‘æ§
    if st.sidebar.checkbox("æ˜¾ç¤ºç³»ç»Ÿèµ„æº"):
        show_system_monitor()

def show_system_monitor():
    """æ˜¾ç¤ºç³»ç»Ÿèµ„æºç›‘æ§"""
    st.sidebar.subheader("ç³»ç»Ÿèµ„æºç›‘æ§")
    
    # CPUä½¿ç”¨ç‡
    cpu_percent = psutil.cpu_percent()
    st.sidebar.metric("CPUä½¿ç”¨ç‡", f"{cpu_percent}%")
    st.sidebar.progress(cpu_percent / 100)
    
    # å†…å­˜ä½¿ç”¨
    mem = psutil.virtual_memory()
    st.sidebar.metric("å†…å­˜ä½¿ç”¨", 
                     f"{mem.used/1024/1024:.1f}MB / {mem.total/1024/1024:.1f}MB",
                     f"{mem.percent}%")
    
    # GPUä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if torch.cuda.is_available():
        gpu_info = get_gpu_memory()
        if gpu_info:
            st.sidebar.subheader("GPUæ˜¾å­˜ä¿¡æ¯")
            st.sidebar.metric(
                "æ€»æ˜¾å­˜", 
                f"{gpu_info['total']:.1f} GB",
                f"å·²ç”¨: {gpu_info['used']:.1f} GB"
            )
            st.sidebar.progress(gpu_info['used'] / gpu_info['total'])


# ========================
# ä¸»ç¨‹åº
# ========================
if __name__ == "__main__":

    # åœ¨å…¨å±€å˜é‡æˆ–session_stateä¸­æ·»åŠ è¿è¡ŒçŠ¶æ€æ ‡å¿—
    if 'running_process' not in st.session_state:
        st.session_state.running_process = None

    os.environ.update({
        'PYTHONDONTWRITEBYTECODE': '0',
        'TRANSFORMERS_CACHE': str(SONG_GEN_DIR / "third_party/hub"),
        'HF_HOME': str(SONG_GEN_DIR / "third_party/hub"),
        'NCCL_HOME': '/usr/local/tccl',
        'PYTHONPATH': ":".join([
            str(SONG_GEN_DIR / "codeclm/tokenizer"),
            str(PROJECT_ROOT),
            str(SONG_GEN_DIR / "codeclm/tokenizer/Flow1dVAE"),
            os.getenv('PYTHONPATH', '')
        ])
    })
    Path(os.environ['TRANSFORMERS_CACHE']).mkdir(exist_ok=True)  # ç¡®ä¿ç›®å½•å­˜åœ¨

    # ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
    (PROJECT_ROOT / "output/audios").mkdir(parents=True, exist_ok=True)
    (PROJECT_ROOT / "output/jsonl").mkdir(parents=True, exist_ok=True)
    (PROJECT_ROOT / "input").mkdir(parents=True, exist_ok=True)
    
    # è®¾ç½®å¹¶è¿è¡ŒUI
    setup_ui()
